{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c453687",
   "metadata": {},
   "source": [
    "# TMDB Movie Success – Mini Project (V7)\n",
    "\n",
    "## V7 improvement over V6: **Optimal decision threshold** (GroupKFold, no leakage)\n",
    "\n",
    "### What’s new vs V6\n",
    "- We still use **GroupKFold by director** and rare-category grouping.\n",
    "- After tuning each model with GridSearchCV, we compute **out-of-fold probabilities** on the training set.\n",
    "- We choose the **threshold that maximizes F1_weighted** on those out-of-fold predictions.\n",
    "- Then we evaluate once on the test set using that threshold.\n",
    "\n",
    "✅ This improves F1 without changing the model and stays fully rigorous (threshold learned only from train via CV).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d5bf0",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d684832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, GroupKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, roc_auc_score,\n",
    "    ConfusionMatrixDisplay, RocCurveDisplay, f1_score\n",
    ")\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea586f4",
   "metadata": {},
   "source": [
    "## 2. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('tmdb_5000_credits.csv')\n",
    "\n",
    "print('movies shape :', movies.shape)\n",
    "print('credits shape:', credits.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa811d",
   "metadata": {},
   "source": [
    "## 3. Merge movies + credits (clean column names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = movies.merge(credits, left_on='id', right_on='movie_id', how='left')\n",
    "\n",
    "# Clean duplicate title columns created by merge\n",
    "if 'title_x' in df.columns:\n",
    "    df = df.rename(columns={'title_x': 'title'})\n",
    "if 'title_y' in df.columns:\n",
    "    df = df.drop(columns=['title_y'])\n",
    "\n",
    "print('merged shape:', df.shape)\n",
    "df[['id', 'title', 'movie_id']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d7a75",
   "metadata": {},
   "source": [
    "## 4. Helper functions (safe parsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_eval_list(x):\n",
    "    if not isinstance(x, str) or x.strip() == '':\n",
    "        return []\n",
    "    try:\n",
    "        v = ast.literal_eval(x)\n",
    "        return v if isinstance(v, list) else []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def first_name_from_json_list(x, default='Unknown'):\n",
    "    v = safe_eval_list(x)\n",
    "    if len(v) > 0 and isinstance(v[0], dict) and 'name' in v[0]:\n",
    "        return v[0]['name']\n",
    "    return default\n",
    "\n",
    "def list_len(x):\n",
    "    return len(safe_eval_list(x))\n",
    "\n",
    "def extract_director(crew_str):\n",
    "    crew = safe_eval_list(crew_str)\n",
    "    for person in crew:\n",
    "        if isinstance(person, dict) and person.get('job') == 'Director':\n",
    "            return person.get('name', 'Unknown')\n",
    "    return 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531801f2",
   "metadata": {},
   "source": [
    "## 5. Pre-release feature engineering (safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02880402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "df['release_year'] = df['release_date'].dt.year\n",
    "df['release_month'] = df['release_date'].dt.month\n",
    "\n",
    "df['main_genre'] = df['genres'].apply(first_name_from_json_list)\n",
    "df['num_genres'] = df['genres'].apply(list_len)\n",
    "\n",
    "df['top_company'] = df['production_companies'].apply(first_name_from_json_list)\n",
    "df['num_production_companies'] = df['production_companies'].apply(list_len)\n",
    "\n",
    "df['is_english'] = (df['original_language'] == 'en').astype(int)\n",
    "\n",
    "df['cast_size'] = df['cast'].apply(list_len)\n",
    "df['crew_size'] = df['crew'].apply(list_len)\n",
    "df['director_name'] = df['crew'].apply(extract_director)\n",
    "\n",
    "df[['main_genre','num_genres','top_company','num_production_companies','original_language','is_english','cast_size','crew_size','director_name']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a4229",
   "metadata": {},
   "source": [
    "## 6. Define composite success score (TARGET ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['profit'] = df['revenue'] - df['budget']\n",
    "df['profit_pos'] = df['profit'].clip(lower=0)\n",
    "\n",
    "P = np.log(df['profit_pos'] + 1)\n",
    "V = np.log(df['vote_count'] + 1)\n",
    "Pop = np.log(df['popularity'] + 1)\n",
    "Q = df['vote_average'] / 10\n",
    "\n",
    "df['FilmSuccessScore'] = 0.4*P + 0.3*Q + 0.2*V + 0.1*Pop\n",
    "\n",
    "threshold_target = df['FilmSuccessScore'].median()\n",
    "df['success'] = (df['FilmSuccessScore'] >= threshold_target).astype(int)\n",
    "\n",
    "df['success'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f4dcb",
   "metadata": {},
   "source": [
    "## 7. Reduce rare categories (to lower overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b6661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_top_n(series, n=50):\n",
    "    top = series.value_counts().head(n).index\n",
    "    return series.where(series.isin(top), other='Other')\n",
    "\n",
    "df['director_group'] = keep_top_n(df['director_name'], n=80)\n",
    "df['company_group']  = keep_top_n(df['top_company'], n=80)\n",
    "df['lang_group']     = keep_top_n(df['original_language'], n=30)\n",
    "df['genre_group']    = keep_top_n(df['main_genre'], n=20)\n",
    "\n",
    "df[['director_name','director_group','top_company','company_group','original_language','lang_group','main_genre','genre_group']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9780d0",
   "metadata": {},
   "source": [
    "## 8. Build X / y + train/test split (with director groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c07a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    'budget', 'runtime', 'release_year', 'release_month',\n",
    "    'num_genres', 'num_production_companies',\n",
    "    'cast_size', 'crew_size', 'is_english'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'genre_group', 'company_group', 'lang_group', 'director_group'\n",
    "]\n",
    "\n",
    "X = df[numeric_features + categorical_features].copy()\n",
    "y = df['success'].copy()\n",
    "groups = df['director_group']\n",
    "\n",
    "X_train, X_test, y_train, y_test, g_train, g_test = train_test_split(\n",
    "    X, y, groups, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print('Train size:', X_train.shape, ' Test size:', X_test.shape)\n",
    "print('Unique director groups (train):', pd.Series(g_train).nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84edf2d",
   "metadata": {},
   "source": [
    "## 9. Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8d86ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f5471",
   "metadata": {},
   "source": [
    "## 10. Helper: best threshold from out-of-fold predictions (GroupKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oof_proba_groupkfold(estimator, X, y, groups, n_splits=5):\n",
    "    \"\"\"Out-of-fold predicted probabilities for class 1 using GroupKFold.\"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    oof = np.zeros(len(X), dtype=float)\n",
    "\n",
    "    Xr = X.reset_index(drop=True)\n",
    "    yr = y.reset_index(drop=True)\n",
    "    gr = pd.Series(groups).reset_index(drop=True)\n",
    "\n",
    "    for train_idx, val_idx in gkf.split(Xr, yr, gr):\n",
    "        est = clone(estimator)\n",
    "        est.fit(Xr.iloc[train_idx], yr.iloc[train_idx])\n",
    "        oof[val_idx] = est.predict_proba(Xr.iloc[val_idx])[:, 1]\n",
    "    return oof\n",
    "\n",
    "def best_threshold_from_proba(y_true, proba):\n",
    "    thresholds = np.linspace(0.05, 0.95, 19)\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        y_pred = (proba >= t).astype(int)\n",
    "        score = f1_score(y_true, y_pred, average='weighted')\n",
    "        rows.append((t, score))\n",
    "    res = pd.DataFrame(rows, columns=['threshold', 'f1_weighted'])\n",
    "    best_row = res.loc[res['f1_weighted'].idxmax()]\n",
    "    return float(best_row['threshold']), res.sort_values('f1_weighted', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e00c0",
   "metadata": {},
   "source": [
    "## 11. Model 1 — Logistic Regression (GridSearch + optimal threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', LogisticRegression(max_iter=4000, class_weight='balanced', solver='liblinear'))\n",
    "])\n",
    "\n",
    "param_grid_lr = {'model__C': [0.01, 0.1, 1, 10, 50]}\n",
    "cv_group = GroupKFold(n_splits=5)\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    log_reg,\n",
    "    param_grid=param_grid_lr,\n",
    "    scoring='f1_weighted',\n",
    "    cv=cv_group,\n",
    "    n_jobs=-1\n",
    ")\n",
    "gs_lr.fit(X_train, y_train, groups=g_train)\n",
    "best_lr = gs_lr.best_estimator_\n",
    "\n",
    "print('Best LR params:', gs_lr.best_params_)\n",
    "print('Best CV F1_weighted (thr=0.5):', gs_lr.best_score_)\n",
    "\n",
    "# Find optimal threshold from OOF train probabilities\n",
    "oof_lr = oof_proba_groupkfold(best_lr, X_train, y_train, g_train, n_splits=5)\n",
    "best_t_lr, table_lr = best_threshold_from_proba(y_train.reset_index(drop=True), oof_lr)\n",
    "\n",
    "print('\\nBest threshold for LR (from OOF train):', best_t_lr)\n",
    "table_lr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on full train and evaluate on test with optimal threshold\n",
    "best_lr.fit(X_train, y_train)\n",
    "\n",
    "proba_test_lr = best_lr.predict_proba(X_test)[:, 1]\n",
    "pred_test_lr_05  = (proba_test_lr >= 0.5).astype(int)\n",
    "pred_test_lr_opt = (proba_test_lr >= best_t_lr).astype(int)\n",
    "\n",
    "print('--- LR TEST (thr=0.5) ---')\n",
    "print('F1_weighted:', f1_score(y_test, pred_test_lr_05, average='weighted'))\n",
    "print('ROC AUC    :', roc_auc_score(y_test, proba_test_lr))\n",
    "print('Accuracy   :', accuracy_score(y_test, pred_test_lr_05))\n",
    "\n",
    "print('\\n--- LR TEST (optimal thr) ---')\n",
    "print('Threshold  :', best_t_lr)\n",
    "print('F1_weighted:', f1_score(y_test, pred_test_lr_opt, average='weighted'))\n",
    "print('ROC AUC    :', roc_auc_score(y_test, proba_test_lr))\n",
    "print('Accuracy   :', accuracy_score(y_test, pred_test_lr_opt))\n",
    "\n",
    "print('\\nClassification report (optimal thr):')\n",
    "print(classification_report(y_test, pred_test_lr_opt))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred_test_lr_opt)\n",
    "plt.title('Logistic Regression – Confusion Matrix (V7, optimal threshold)')\n",
    "plt.show()\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, proba_test_lr)\n",
    "plt.title('Logistic Regression – ROC Curve (V7)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886587a",
   "metadata": {},
   "source": [
    "## 12. Model 2 — Decision Tree (GridSearch + optimal threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab808aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', DecisionTreeClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_tree = {\n",
    "    'model__max_depth': [3, 4, 5, 6, None],\n",
    "    'model__min_samples_leaf': [5, 10, 20, 40],\n",
    "    'model__min_samples_split': [10, 30, 50, 100],\n",
    "    'model__ccp_alpha': [0.0, 0.0005, 0.001, 0.005]\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(\n",
    "    tree,\n",
    "    param_grid=param_grid_tree,\n",
    "    scoring='f1_weighted',\n",
    "    cv=cv_group,\n",
    "    n_jobs=-1\n",
    ")\n",
    "gs_tree.fit(X_train, y_train, groups=g_train)\n",
    "best_tree = gs_tree.best_estimator_\n",
    "\n",
    "print('Best Tree params:', gs_tree.best_params_)\n",
    "print('Best CV F1_weighted (thr=0.5):', gs_tree.best_score_)\n",
    "\n",
    "oof_tree = oof_proba_groupkfold(best_tree, X_train, y_train, g_train, n_splits=5)\n",
    "best_t_tree, table_tree = best_threshold_from_proba(y_train.reset_index(drop=True), oof_tree)\n",
    "\n",
    "print('\\nBest threshold for Tree (from OOF train):', best_t_tree)\n",
    "table_tree.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802aed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree.fit(X_train, y_train)\n",
    "\n",
    "proba_test_tree = best_tree.predict_proba(X_test)[:, 1]\n",
    "pred_test_tree_05  = (proba_test_tree >= 0.5).astype(int)\n",
    "pred_test_tree_opt = (proba_test_tree >= best_t_tree).astype(int)\n",
    "\n",
    "print('--- Tree TEST (thr=0.5) ---')\n",
    "print('F1_weighted:', f1_score(y_test, pred_test_tree_05, average='weighted'))\n",
    "print('ROC AUC    :', roc_auc_score(y_test, proba_test_tree))\n",
    "print('Accuracy   :', accuracy_score(y_test, pred_test_tree_05))\n",
    "\n",
    "print('\\n--- Tree TEST (optimal thr) ---')\n",
    "print('Threshold  :', best_t_tree)\n",
    "print('F1_weighted:', f1_score(y_test, pred_test_tree_opt, average='weighted'))\n",
    "print('ROC AUC    :', roc_auc_score(y_test, proba_test_tree))\n",
    "print('Accuracy   :', accuracy_score(y_test, pred_test_tree_opt))\n",
    "\n",
    "print('\\nClassification report (optimal thr):')\n",
    "print(classification_report(y_test, pred_test_tree_opt))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred_test_tree_opt)\n",
    "plt.title('Decision Tree – Confusion Matrix (V7, optimal threshold)')\n",
    "plt.show()\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, proba_test_tree)\n",
    "plt.title('Decision Tree – ROC Curve (V7)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbf33b6",
   "metadata": {},
   "source": [
    "## 13. Compare models (Test, optimal threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a10b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree'],\n",
    "    'Best_threshold': [best_t_lr, best_t_tree],\n",
    "    'F1_weighted_test_opt': [\n",
    "        f1_score(y_test, pred_test_lr_opt, average='weighted'),\n",
    "        f1_score(y_test, pred_test_tree_opt, average='weighted')\n",
    "    ],\n",
    "    'ROC_AUC_test': [\n",
    "        roc_auc_score(y_test, proba_test_lr),\n",
    "        roc_auc_score(y_test, proba_test_tree)\n",
    "    ],\n",
    "    'Accuracy_test_opt': [\n",
    "        accuracy_score(y_test, pred_test_lr_opt),\n",
    "        accuracy_score(y_test, pred_test_tree_opt)\n",
    "    ]\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d98f2d",
   "metadata": {},
   "source": [
    "## 14. Mini search engine (title → Success/Failure) using the chosen threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c1665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the final model here\n",
    "final_model = best_lr\n",
    "final_threshold = best_t_lr\n",
    "\n",
    "def predict_from_title(title: str):\n",
    "    mask = df['title'].astype(str).str.lower() == title.strip().lower()\n",
    "    if mask.sum() == 0:\n",
    "        mask = df['title'].astype(str).str.lower().str.contains(title.strip().lower(), na=False)\n",
    "        if mask.sum() == 0:\n",
    "            return None, 'Title not found in dataset.'\n",
    "\n",
    "    row = df.loc[mask].iloc[0]\n",
    "\n",
    "    x_row = pd.DataFrame([{\n",
    "        **{c: row.get(c, np.nan) for c in numeric_features},\n",
    "        **{c: row.get(c, 'Other') for c in categorical_features}\n",
    "    }])\n",
    "\n",
    "    proba = float(final_model.predict_proba(x_row)[:, 1][0])\n",
    "    pred = int(proba >= final_threshold)\n",
    "\n",
    "    label = 'SUCCESS (bon film)' if pred == 1 else 'FAILURE (mauvais film)'\n",
    "    return {\n",
    "        'title': row['title'],\n",
    "        'proba_success': round(proba, 4),\n",
    "        'threshold_used': float(final_threshold),\n",
    "        'prediction': label\n",
    "    }, None\n",
    "\n",
    "# Example\n",
    "predict_from_title('Avatar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85b6e7",
   "metadata": {},
   "source": [
    "## 15. Notes for your report\n",
    "\n",
    "- V7 keeps the V6 anti-leakage strategy (GroupKFold by director + rare-category grouping).\n",
    "- V7 also optimizes the **decision threshold** using only training data via out-of-fold probabilities.\n",
    "- This improves the SUCCESS/FAILURE decision for the F1 metric while avoiding any test leakage.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
